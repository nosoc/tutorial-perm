---
title: "Tutorial Perm"
output: html_document
---

# First task
```{r}
library(lsa)
library(jsonlite)
library(stringr)
library(dplyr)
library(readr)
library(recommenderlab)
library(tidyr)
library(reshape2)
```

Загрузка данных

```{r}
load("~/tutorial_data.rda")
```

Выбираем колонку с оценками и пользователями, сделаем матрицу.

```{r}
rates = select(j, reviewerID, asin, overall)
rates = spread(rates, key = asin, value = overall)
rownames(rates) = rates$reviewerID
rates = select(rates, -reviewerID)
rates = as.matrix(rates)
r = as(rates, "realRatingMatrix")
r
```


### Похожесть по оценкам

Похожесть (similarity) может определяться разными способами

* Коэффициент Пирсона;
* Косинусное расстояние;
* Евклидово расстояние.

### Предварительная подготовка данных

Сначала подготовим данные, в частности, уберем те, что являются нерелевантными. 

Если фильм редкий, его мало кто видел, то оценки для него могут быть сильно смещенными. Так же и для пользователя -- если он оценил малое число фильмов, то ему сложно дать рекомендацию. 

Как определить, что является "малым числом"? В общем случае -- итерационно, т.е. отбираем данные, строим модель, оцениваем ее и так несколько раз. В данном примере рассмотрим только один шаг -- будем считать, что нас интересуют фильмы с не менее 10 оценками и пользователи, поставившие не менее 5 оценок.

Количество оценок у фильма можно посчитать с помощью функции colCounts(), а количество оценок, поставленных одним пользователем -- с помощью rowCounts(). 

```{r}
library(ggplot2)
ggplot(data = data.frame(filmRate=colCounts(r))) + geom_histogram(aes(x=filmRate))

ggplot(data = data.frame(userRate=rowCounts(r))) + geom_histogram(aes(x=userRate))
```

Отберем только строки и столбцы с нужным количеством оценок

```{r}
ratings_movies <- r[rowCounts(r) > 5, colCounts(r) > 10] 
ratings_movies
```
### Метод коллаборативной фильтрации

* вычислить похожесть всех пар фильмов
* для каждого фильма найти k наиболее похожих
* для каждого пользователя определить фильмы, наиболее близкие к тем, которые он оценил

Разделим данные на тестовую и обучающую выборки. На обучающей построим модель, для пользователей из тестовой будем рекомендовать фильмы.


```{r}
set.seed(100)
test_ind <- sample(1:nrow(ratings_movies), size = nrow(ratings_movies)*0.2)
recc_data_train <- ratings_movies[-test_ind, ]
recc_data_test <- ratings_movies[test_ind, ]
```


Возможны разные методы построения модели. Рассмотрим метод IBCF ("Recommender based on item-based collaborative filtering (real data).")

Построим рекомендательную модель
```{r}
recc_model <- Recommender(data = recc_data_train, method = "IBCF", parameter = list(k = 30))
recc_model
```

Детали этой модели можно получить с помощью метода getModel(), например, матрицу схожести

```{r}
model_details <- getModel(recc_model)
model_details$description
model_details$sim[1:5, 1:5]
```

Рекомендации

* для каждого пользователя извлекаются те фильмы, которые он оценил
* для каждого из фильмов находятся похожие фильмы
* затем фильмы упорядочиваются согласно весам, где вес каждой рекомендации (фильма) вычисляется на основе оценок пользователя и показателей схожести фильмов (взвешенная сумма)

```{r}
recc_predicted <- predict(object = recc_model, newdata = recc_data_test, n = 6)
recc_predicted
```

Посмотрим на результат
```{r}
str(recc_predicted)
```

Слоты (доступ через символ @) 

* items -- содержит индексы рекомендованных фильмов для каждого пользователя
* itemLabels -- названия фильмов
* ratings -- рейтинги рекомендаций
* n -- число рекомендаций

Рекомендации для первого пользователя
```{r}
recc_user_1 <- recc_predicted@items[[15]]
recc_user_1
```

Это результат в виде номер строк в матрице, вытащим id фильмов

```{r}
movies_user_1 <- recc_predicted@itemLabels[recc_user_1]
movies_user_1
```
А теперь посмотрим на названия. Функция `match` возвращает позицию, на которой элементы из первого параметра встретились во втором (см. `?match`)

```{r}
names_movies_user_1 <- jmeta$title[match(movies_user_1, jmeta$asin)]
names_movies_user_1
```


# Рекомендации основанные на содержании

```{r}
library(tidytext)
movie_metadata = movie_metadata %>% select(movie_title,genres)
movie_metadata = movie_metadata[!duplicated(movie_metadata),]
movie_metadata$genres = movie_metadata$genres %>% str_replace_all(regex(" |-"),"") %>%  str_replace_all(fixed("|")," ")
movie_metadata$id = 1:nrow(movie_metadata)
movie_metadata = movie_metadata %>% unnest_tokens(genres,genres)
movie_metadata$is_g = 1
movie_metadata = movie_metadata %>% spread(genres,is_g,fill=0)
```

Возьмем небольшой кусочек данных, потому что на всех фильмах будет долго считаться.

```{r}
movie_rec = movie_metadata[sample(nrow(movie_metadata), 1000),]
rownames(movie_rec) = movie_rec$movie_title
movie_rec$movie_title = NULL
movie_rec$id = NULL
movie_rec = as.matrix(movie_rec)

```

Посчитаем косинусное расстояние между фильмами на основе общих жанров. 

```{r}
dist = cosine(t(movie_rec))
```

Допустим кто-то поставил первому фильму в матрице наивысшую оценку. Какие фильмы мы им порекомендуем?

```{r}
rownames(movie_rec)[1]
rec_movies = names(tail(sort(dist[rownames(movie_rec)[1],]),5))
rec_movies
```